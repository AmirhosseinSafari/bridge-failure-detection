{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5_When_rebuilding.csv',\n",
       " '1_After_reconstruction.csv',\n",
       " '1_When_rebuilding.csv',\n",
       " '2_Before_renovation.csv',\n",
       " '6_After_reconstruction.csv',\n",
       " '2_When_rebuilding.csv',\n",
       " '4_Before_renovation.csv',\n",
       " '5_After_reconstruction.csv',\n",
       " '3_When_rebuilding.csv',\n",
       " '3_After_reconstruction.csv',\n",
       " '6_Before_renovation.csv',\n",
       " '4_After_reconstruction.csv',\n",
       " '1_Before_renovation.csv',\n",
       " '3_Before_renovation.csv',\n",
       " '6_When_rebuilding.csv',\n",
       " '2_After_reconstruction.csv',\n",
       " '5_Before_renovation.csv',\n",
       " '4_When_rebuilding.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Geting csv files\n",
    "list_of_files = os.listdir(\"./\")\n",
    "csv_files = []\n",
    "\n",
    "for _file in list_of_files:\n",
    "    if _file.endswith(\".csv\"):\n",
    "        csv_files.append(_file)\n",
    "\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_slicer(signal, fs=825.8):\n",
    "    '''\n",
    "    Returns: first 10 seconds\n",
    "             last 30 seconds of the signal\n",
    "    '''\n",
    "\n",
    "    return signal[:int(fs * 10)].reshape(int(fs * 10), 1), signal[int(-30 * fs):].reshape(int(30 * fs), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicer(signal, fs=825.8, chunk_size_seconds=10):\n",
    "    '''\n",
    "    Returns: sliced signal in desired seconds chunks\n",
    "    Note: size of the signal should be a true nominator of chunk size\n",
    "    '''\n",
    "    chunk_size = int(fs * chunk_size_seconds)\n",
    "    return [signal[_ * chunk_size : (_+1)*chunk_size ].reshape(int(10 * fs), 1) for _ in range(int(len(signal)/chunk_size))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_to_heatmap(signal):\n",
    "    '''\n",
    "    Returns the heatmap of signal\n",
    "    '''\n",
    "    # Desired size in pixels\n",
    "    width_px = 600\n",
    "    height_px = 600\n",
    "\n",
    "    # DPI (dots per inch)\n",
    "    dpi = 300\n",
    "\n",
    "    # Convert to inches\n",
    "    width_in = width_px / dpi\n",
    "    height_in = height_px / dpi\n",
    "\n",
    "    # Set the size of the heatmap\n",
    "    plt.figure(figsize=(width_in, height_in), dpi=dpi)\n",
    "    \n",
    "    sns.heatmap(signal, xticklabels=False, yticklabels=False, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_creator(csv_file_name, columns):\n",
    "    '''\n",
    "    Creating directoies for each column of csv files\n",
    "        to save heatmaps into them\n",
    "    '''\n",
    "    file_name = csv_file_name.split('.')[0]\n",
    "    os.mkdir(file_name)\n",
    "    for _ in range(columns):\n",
    "        os.mkdir(f\"{file_name}/{_}\")\n",
    "        os.mkdir(f\"{file_name}/{_}/train_out\")\n",
    "        os.mkdir(f\"{file_name}/{_}/train_in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_heatmap(csv_file_name, column, counter, train_status):\n",
    "    '''\n",
    "    Saving plots in png format in their specific path\n",
    "    '''\n",
    "    path = f\"{csv_file_name.split('.')[0]}/{column}/{train_status}/{csv_file_name}_{column}_{counter}.png\"\n",
    "    plt.savefig(path , dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_five_zeros(arr):\n",
    "    \"\"\"Remove sequences of 5 successive zeros from an array.\"\"\"\n",
    "    result = []\n",
    "    zero_count = 0\n",
    "\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] == 0:\n",
    "            zero_count += 1\n",
    "        else:\n",
    "            if zero_count == 5:\n",
    "                result = result[:-5]  # Remove the last 5 zeros from the result\n",
    "            zero_count = 0\n",
    "            result.append(arr[i])\n",
    "        \n",
    "        # If we've reached the end and have exactly 5 zeros at the end\n",
    "        if i == len(arr) - 1 and zero_count == 5:\n",
    "            result = result[:-5]\n",
    "    \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing fs\n",
    "fs=825.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and processing csv files\n",
    "for csv_file in csv_files:\n",
    "    # Reading files\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Nan to zero\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    # Loading each column of df into dict\n",
    "    columns_dict = {}\n",
    "    for col in df.columns:\n",
    "        columns_dict[col] = df[col].to_numpy()\n",
    "    # Removing first incremental column\n",
    "    columns_dict.pop('Unnamed: 0') \n",
    "\n",
    "    # Creating dirs\n",
    "    dir_creator(csv_file, len(columns_dict.keys()))\n",
    "\n",
    "    heatmaps_counter = 1\n",
    "\n",
    "    for col in columns_dict.keys():\n",
    "        # Removing 5 successive zeros\n",
    "        columns_dict[col] = remove_five_zeros(columns_dict[col])\n",
    "\n",
    "        # handling train out part\n",
    "        first_10, last_30 = custom_slicer(columns_dict[col], fs)\n",
    "        last_30_signals_chunked = slicer(last_30)\n",
    "\n",
    "        signal_to_heatmap(first_10)\n",
    "        save_heatmap(csv_file, col, heatmaps_counter, \"train_out\")\n",
    "        heatmaps_counter += 1\n",
    "        \n",
    "        for sig_chunk in last_30_signals_chunked:\n",
    "            signal_to_heatmap(sig_chunk)\n",
    "            save_heatmap(csv_file, col, heatmaps_counter, \"train_out\")\n",
    "            heatmaps_counter += 1\n",
    "        \n",
    "        # handling train in part\n",
    "        train_in_sig_chunks = slicer(columns_dict[col][10:-30])\n",
    "        for sig_chunk in train_in_sig_chunks:\n",
    "            signal_to_heatmap(sig_chunk)\n",
    "            save_heatmap(csv_file, col, heatmaps_counter, \"train_in\")\n",
    "            heatmaps_counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
